{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Lab 5 (bag-of-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0. Build an N-gram language model based on some corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('this', 'is'): 3, ('another', 'example'): 2, ('is', 'a'): 1, ('a', 'sample'): 1, ('sample', 'sentence'): 1, ('is', 'another'): 1, ('example', 'sentence'): 1, ('is', 'yet'): 1, ('yet', 'another'): 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Зразковий корпус\n",
    "corpus = [\n",
    "    \"this is a sample sentence\",\n",
    "    \"this is another example sentence\",\n",
    "    \"this is yet another example\"\n",
    "]\n",
    "\n",
    "# Токенізація корпусу\n",
    "tokenized_corpus = [nltk.word_tokenize(sentence) for sentence in corpus]\n",
    "\n",
    "# Функція для побудови N-грамної моделі\n",
    "def build_ngram_model(tokenized_corpus, n):\n",
    "    ngrams_list = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        ngrams_list.extend(list(ngrams(sentence, n)))\n",
    "    \n",
    "    ngram_freq = Counter(ngrams_list)\n",
    "    return ngram_freq\n",
    "\n",
    "# Побудова біграмної моделі (2-грам)\n",
    "bigram_model = build_ngram_model(tokenized_corpus, 2)\n",
    "print(bigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Compare bi- and tri-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Model: Counter({('this', 'is', 'a'): 1, ('is', 'a', 'sample'): 1, ('a', 'sample', 'sentence'): 1, ('this', 'is', 'another'): 1, ('is', 'another', 'example'): 1, ('another', 'example', 'sentence'): 1, ('this', 'is', 'yet'): 1, ('is', 'yet', 'another'): 1, ('yet', 'another', 'example'): 1})\n",
      "Bigram Model: Counter({('this', 'is'): 3, ('another', 'example'): 2, ('is', 'a'): 1, ('a', 'sample'): 1, ('sample', 'sentence'): 1, ('is', 'another'): 1, ('example', 'sentence'): 1, ('is', 'yet'): 1, ('yet', 'another'): 1})\n",
      "Trigram Model: Counter({('this', 'is', 'a'): 1, ('is', 'a', 'sample'): 1, ('a', 'sample', 'sentence'): 1, ('this', 'is', 'another'): 1, ('is', 'another', 'example'): 1, ('another', 'example', 'sentence'): 1, ('this', 'is', 'yet'): 1, ('is', 'yet', 'another'): 1, ('yet', 'another', 'example'): 1})\n"
     ]
    }
   ],
   "source": [
    "# Build a trigram model (3-gram)\n",
    "trigram_model = build_ngram_model(tokenized_corpus, 3)\n",
    "print(\"Trigram Model:\", trigram_model)\n",
    "\n",
    "# Compare bigram and trigram models\n",
    "print(\"Bigram Model:\", bigram_model)\n",
    "print(\"Trigram Model:\", trigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Apply interpolation/backoff to your model so that it can better handle unknown words/prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated probability for ('this', 'is', 'a'): 0.09833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Function to build unigram model\n",
    "def build_unigram_model(tokenized_corpus):\n",
    "    unigrams_list = [token for sentence in tokenized_corpus for token in sentence]\n",
    "    unigram_freq = Counter(unigrams_list)\n",
    "    return unigram_freq\n",
    "\n",
    "# Build unigram model\n",
    "unigram_model = build_unigram_model(tokenized_corpus)\n",
    "\n",
    "# Function to calculate interpolated probability\n",
    "def interpolated_prob(word_sequence, unigram_model, bigram_model, trigram_model, lambda1=0.1, lambda2=0.3, lambda3=0.6):\n",
    "    if len(word_sequence) == 1:\n",
    "        return unigram_model[word_sequence[0]] / sum(unigram_model.values())\n",
    "    elif len(word_sequence) == 2:\n",
    "        unigram_prob = unigram_model[word_sequence[1]] / sum(unigram_model.values())\n",
    "        bigram_prob = bigram_model[word_sequence] / sum(bigram_model.values())\n",
    "        return lambda1 * unigram_prob + lambda2 * bigram_prob\n",
    "    elif len(word_sequence) == 3:\n",
    "        unigram_prob = unigram_model[word_sequence[2]] / sum(unigram_model.values())\n",
    "        bigram_prob = bigram_model[word_sequence[1:]] / sum(bigram_model.values())\n",
    "        trigram_prob = trigram_model[word_sequence] / sum(trigram_model.values())\n",
    "        return lambda1 * unigram_prob + lambda2 * bigram_prob + lambda3 * trigram_prob\n",
    "\n",
    "# Example usage\n",
    "word_sequence = ('this', 'is', 'a')\n",
    "prob = interpolated_prob(word_sequence, unigram_model, bigram_model, trigram_model)\n",
    "print(f\"Interpolated probability for {word_sequence}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Use this model to build sentences. Meaning, for a prompt consisting of words p_1, ..., p_n, it should produce a continuation w_1, ..., w_k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence: this is a sample sentence this is a sample sentence\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(prompt, unigram_model, bigram_model, trigram_model, max_length=10):\n",
    "    sentence = list(prompt)\n",
    "    # Generate the continuation of the sentence\n",
    "    while len(sentence) < max_length:\n",
    "        if len(sentence) >= 2:\n",
    "            trigram_candidates = [(trigram, prob) for trigram, prob in trigram_model.items() if trigram[:2] == tuple(sentence[-2:])]\n",
    "            if trigram_candidates:\n",
    "                next_word = max(trigram_candidates, key=lambda x: x[1])[0][2]\n",
    "                sentence.append(next_word)\n",
    "                continue\n",
    "        \n",
    "        if len(sentence) >= 1:\n",
    "            bigram_candidates = [(bigram, prob) for bigram, prob in bigram_model.items() if bigram[0] == sentence[-1]]\n",
    "            if bigram_candidates:\n",
    "                next_word = max(bigram_candidates, key=lambda x: x[1])[0][1]\n",
    "                sentence.append(next_word)\n",
    "                continue\n",
    "        \n",
    "        unigram_candidates = [(unigram, prob) for unigram, prob in unigram_model.items()]\n",
    "        next_word = max(unigram_candidates, key=lambda x: x[1])[0]\n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example usage\n",
    "prompt = ('this', 'is')\n",
    "generated_sentence = generate_sentence(prompt, unigram_model, bigram_model, trigram_model)\n",
    "print(f\"Generated sentence: {generated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
