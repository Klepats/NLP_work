{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0. Using https://www.nltk.org/howto/corpus.html#overview, implement TF-IDF vectorizer for e.g. Treebank corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['00' '000' '00021053' ... 'zurishaddai' 'zuyder' 'zuzims']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Завантажуємо всі речення з корпусу Treebank\n",
    "sentences = gutenberg.sents()\n",
    "\n",
    "# Перетворюємо речення в рядки, об'єднуючи слова\n",
    "documents = [' '.join(sentence) for sentence in sentences]\n",
    "\n",
    "# Ініціалізуємо TfidfVectorizer для перетворення тексту в числові вектори\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Навчаємо та перетворюємо документи на TF-IDF матрицю\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Отримуємо імена фіч (слова, які використовуються у документах)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Перетворюємо матрицю TF-IDF в щільний формат і виводимо її\n",
    "dense_tfidf_matrix = tfidf_matrix[:1000].todense()  # Convert only the first 1000 rows to dense format\n",
    "print(dense_tfidf_matrix)\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['00' '000' '004' ... 'zoomed' 'zuckerman' 'zurich']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg, treebank\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Завантажуємо всі речення з корпусу Treebank\n",
    "sentences = treebank.sents()\n",
    "\n",
    "# Перетворюємо речення в рядки, об'єднуючи слова\n",
    "documents = [' '.join(sentence) for sentence in sentences]\n",
    "\n",
    "# Ініціалізуємо TfidfVectorizer для перетворення тексту в числові вектори\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Навчаємо та перетворюємо документи на TF-IDF матрицю\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Отримуємо імена фіч (слова, які використовуються у документах)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Перетворюємо матрицю TF-IDF в щільний формат і виводимо її\n",
    "dense_tfidf_matrix = tfidf_matrix.todense()  # Convert only the first 1000 rows to dense format\n",
    "print(dense_tfidf_matrix)\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\kleot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Завантажуємо корпус Treebank\n",
    "nltk.download('treebank')\n",
    "\n",
    "# Завантажуємо всі речення з корпусу Treebank\n",
    "sentences = treebank.sents()\n",
    "\n",
    "# Перетворюємо речення в рядки, об'єднуючи слова\n",
    "documents = [' '.join(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Створення Bag-of-Words моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words представлення:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Ініціалізуємо CountVectorizer (для Bag-of-Words)\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Навчаємо та перетворюємо документи на матрицю термін-документ\n",
    "bow_matrix = bow_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Отримуємо список всіх слів (feature names)\n",
    "bow_feature_names = bow_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Перетворюємо матрицю в щільний формат і виводимо\n",
    "dense_bow_matrix = bow_matrix.todense()\n",
    "\n",
    "print(\"Bag-of-Words представлення:\")\n",
    "print(dense_bow_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обчислення TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF представлення:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Ініціалізуємо TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Навчаємо та перетворюємо документи на TF-IDF матрицю\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Отримуємо імена фіч для TF-IDF\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Перетворюємо TF-IDF матрицю в щільний формат і виводимо\n",
    "dense_tfidf_matrix = tfidf_matrix.todense()\n",
    "\n",
    "print(\"\\nTF-IDF представлення:\")\n",
    "print(dense_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обчислення PPMI (Positive Pointwise Mutual Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kleot\\AppData\\Local\\Temp\\ipykernel_21364\\2100767066.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  ppmi_matrix = np.maximum(0, np.log((co_occurrence_matrix * num_docs) /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPMI матриця:\n",
      "[[1.14141632 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         1.53772349 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.99714283 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.99714283 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         3.14241643]]\n",
      "\n",
      "Перші 10 слів Bag-of-Words:\n",
      "['00' '000' '004' '0085' '01' '03' '04' '040' '05' '050']\n",
      "\n",
      "Перші 10 слів TF-IDF:\n",
      "['00' '000' '004' '0085' '01' '03' '04' '040' '05' '050']\n"
     ]
    }
   ],
   "source": [
    "# Створюємо термін-термін матрицю (для простоти використовуємо кількість появ слів разом)\n",
    "co_occurrence_matrix = np.dot(bow_matrix.T, bow_matrix).todense()\n",
    "\n",
    "# Загальна кількість документів\n",
    "num_docs = bow_matrix.shape[0]\n",
    "\n",
    "# Рахуємо PPMI\n",
    "ppmi_matrix = np.maximum(0, np.log((co_occurrence_matrix * num_docs) /\n",
    "                                   (np.dot(np.sum(co_occurrence_matrix, axis=1).reshape(-1, 1),\n",
    "                                           np.sum(co_occurrence_matrix, axis=0).reshape(1, -1)))))\n",
    "\n",
    "print(\"\\nPPMI матриця:\")\n",
    "print(ppmi_matrix)\n",
    "\n",
    "# Для порівняння, можна вивести кілька перших слів для кожної матриці\n",
    "print(\"\\nПерші 10 слів Bag-of-Words:\")\n",
    "print(bow_feature_names[:10])\n",
    "\n",
    "print(\"\\nПерші 10 слів TF-IDF:\")\n",
    "print(tfidf_feature_names[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
